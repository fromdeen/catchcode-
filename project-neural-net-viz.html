<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NeuralNet Data Visualizer - Prototype</title>
    <style>
        body {
            font-family: 'Consolas', 'Monaco', monospace;
            background-color: #000000;
            color: #FF0000;
            margin: 0;
            padding: 0;
            overflow: hidden;
            cursor: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><text x="0" y="14" font-family="monospace" font-size="14" fill="%23FF0000">_</text></svg>') 8 8, auto;
        }

        .matrix-background {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: repeating-linear-gradient(
                0deg,
                rgba(255,0,0,0.05),
                rgba(255,0,0,0.05) 1px,
                transparent 1px,
                transparent 2px
            ), url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="100" height="100" fill="%23FF0000" opacity="0.02"><rect width="100" height="100" fill="%23000000"/><path d="M 0 0 L 100 100 M 100 0 L 0 100" stroke="%23FF0000" stroke-width="1"/></svg>');
            background-size: 100% 100%, 20px 20px;
            animation: matrixFlow 10s linear infinite;
            z-index: -1;
            opacity: 0.8;
        }

        @keyframes matrixFlow {
            from { background-position: 0 0, 0 0; }
            to { background-position: 0 100%, 100% 100%; }
        }

        .terminal-container {
            width: 90%;
            max-width: 1000px;
            height: 90vh;
            margin: 5vh auto;
            border: 2px solid #FF0000;
            box-shadow: 0 0 50px rgba(255, 0, 0, 0.8);
            background-color: rgba(0, 0, 0, 0.9);
            display: flex;
            flex-direction: column;
            overflow: hidden;
            position: relative;
        }

        .terminal-header {
            background-color: #FF0000;
            color: #000000;
            padding: 8px 15px;
            font-size: 0.9em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .terminal-header .controls span {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-left: 5px;
            cursor: pointer;
        }
        .terminal-header .controls .close { background-color: #FF4500; }
        .terminal-header .controls .minimize { background-color: #FFD700; }
        .terminal-header .controls .maximize { background-color: #00FF00; }

        .terminal-output {
            flex-grow: 1;
            padding: 20px;
            overflow-y: auto;
            white-space: pre-wrap;
            font-size: 1.1em;
            line-height: 1.4;
            color: #FF0000;
            position: relative;
        }

        .terminal-output::after {
            content: '_';
            animation: blink-caret .75s step-end infinite;
        }

        .terminal-input-line {
            display: flex;
            padding: 10px 20px;
            border-top: 1px solid rgba(255, 0, 0, 0.3);
        }

        .terminal-input-line span {
            color: #FFD700; /* Gold for prompt */
            margin-right: 5px;
        }

        .terminal-input {
            background: none;
            border: none;
            color: #FF0000;
            flex-grow: 1;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 1.1em;
            outline: none;
            caret-color: #FF0000;
        }

        .interactive-button {
            background-color: #FF0000;
            color: #000000;
            border: 1px solid #FF0000;
            padding: 8px 15px;
            font-size: 0.9em;
            cursor: pointer;
            margin-top: 10px;
            box-shadow: 0 0 10px rgba(255, 0, 0, 0.5);
            transition: background-color 0.3s ease, color 0.3s ease, box-shadow 0.3s ease;
        }

        .interactive-button:hover {
            background-color: #000000;
            color: #FF0000;
            box-shadow: 0 0 20px rgba(255, 0, 0, 0.9);
        }

        .back-button {
            position: absolute;
            top: 20px;
            left: 20px;
            background-color: #FF0000;
            color: #000000;
            border: 2px solid #FF0000;
            padding: 10px 20px;
            font-size: 1em;
            cursor: pointer;
            z-index: 100;
            box-shadow: 0 0 15px rgba(255, 0, 0, 0.7);
            transition: background-color 0.3s ease, color 0.3s ease, box-shadow 0.3s ease;
        }

        .back-button:hover {
            background-color: #000000;
            color: #FF0000;
            box-shadow: 0 0 25px rgba(255, 0, 0, 0.9);
        }

        /* Typing animation for output */
        .typing-text {
            overflow: hidden;
            white-space: pre-wrap;
            border-right: .15em solid transparent; /* Initial transparent caret */
            animation: typing-output 0s steps(1, end) forwards; /* Will be set by JS */
        }

        @keyframes typing-output {
            from { width: 0 }
            to { width: 100% }
        }

        @keyframes blink-caret {
            from, to { border-color: transparent }
            50% { border-color: #FF0000; }
        }
    </style>
</head>
<body>
    <div class="matrix-background"></div>
    <a href="index.html" class="back-button" onclick="playButtonClickSound()">‚Üê BACK TO PORTFOLIO</a>

    <div class="terminal-container">
        <div class="terminal-header">
            <span>NeuralNet Data Visualizer // Real-time Inference Monitoring (Kredivo - FinAccel)</span>
            <div class="controls">
                <span class="minimize"></span>
                <span class="maximize"></span>
                <span class="close" onclick="window.location.href='index.html'"></span>
            </div>
        </div>
        <div class="terminal-output" id="terminalOutput">
            <span class="typing-text" id="initialOutput">
                &gt; [LINK] Establishing Secure Data Channel to NeuralNet Cluster... [STATUS: CONNECTED]
                &gt; [STREAM] Fetching Real-time Inference Data (TensorFlow/PyTorch)... [STATUS: STREAMING]
                &gt; [VISUALIZE] Neuron Activation Patterns & Model Confidence Scores...
                &gt; [ANOMALY] Detection Threshold: 0.02 (Adaptive)
                &gt; [METRICS] Current Throughput: 1500 inferences/sec | Latency: 12ms
                &gt; [HEALTH] Network Health: Optimal.
                &gt; [PREDICT] Displaying Predictive Analytics & Trend Forecasting.
                &gt;
                &gt; Type 'help' for commands or 'fetch_live_data' to update visuals.
            </span>
        </div>
        <div class="terminal-input-line">
            <span>nn-viz@cluster:~#</span>
            <input type="text" class="terminal-input" id="terminalInput" autofocus>
        </div>
    </div>

    <!-- Audio Elements for Prototype Page -->
    <audio id="typingSound" src="audio/typing.mp3" preload="auto"></audio>
    <audio id="accessGrantedSound" src="audio/access_granted.mp3" preload="auto"></audio>
    <audio id="accessDeniedSound" src="audio/access_denied.mp3" preload="auto"></audio>
    <audio id="scanSound" src="audio/scan.mp3" preload="auto"></audio>
    <audio id="alertSound" src="audio/alert.mp3" preload="auto"></audio>
    <audio id="successSound" src="audio/success.mp3" preload="auto"></audio>
    <audio id="buttonClickSound" src="audio/button_click.mp3" preload="auto"></audio>
    <audio id="dataTransferSound" src="audio/data_transfer.mp3" preload="auto"></audio>


    <script>
        const terminalOutput = document.getElementById('terminalOutput');
        const terminalInput = document.getElementById('terminalInput');
        const initialOutputSpan = document.getElementById('initialOutput');

        // Audio elements
        const typingSound = document.getElementById('typingSound');
        const accessGrantedSound = document.getElementById('accessGrantedSound');
        const accessDeniedSound = document.getElementById('accessDeniedSound');
        const scanSound = document.getElementById('scanSound');
        const alertSound = document.getElementById('alertSound');
        const successSound = document.getElementById('successSound');
        const buttonClickSound = document.getElementById('buttonClickSound');
        const dataTransferSound = document.getElementById('dataTransferSound');

        function playSound(audioElement) {
            if (audioElement) {
                audioElement.currentTime = 0;
                audioElement.play().catch(e => console.log("Audio play failed:", e));
            }
        }

        function playButtonClickSound() {
            playSound(buttonClickSound);
        }

        // Simulate typing effect
        function typeText(element, text, speed = 30, callback) {
            let i = 0;
            element.textContent = '';
            playSound(typingSound);
            const interval = setInterval(() => {
                if (i < text.length) {
                    element.textContent += text.charAt(i);
                    terminalOutput.scrollTop = terminalOutput.scrollHeight;
                    i++;
                } else {
                    clearInterval(interval);
                    typingSound.pause();
                    if (callback) callback();
                }
            }, speed);
        }

        // Initial output typing
        document.addEventListener('DOMContentLoaded', () => {
            const textToType = initialOutputSpan.textContent;
            initialOutputSpan.textContent = '';
            typeText(initialOutputSpan, textToType, 20, () => {
                terminalInput.focus();
            });
        });

        terminalInput.addEventListener('keydown', function(event) {
            if (event.key === 'Enter') {
                event.preventDefault();
                const command = terminalInput.value.trim();
                terminalInput.value = '';
                processCommand(command);
            }
        });

        async function appendOutput(text, isCommand = false) {
            const newSpan = document.createElement('span');
            newSpan.className = 'typing-text';
            if (isCommand) {
                newSpan.textContent = `nn-viz@cluster:~# ${text}\n`;
            } else {
                newSpan.textContent = text + '\n';
            }
            terminalOutput.appendChild(newSpan);
            terminalOutput.scrollTop = terminalOutput.scrollHeight;
            await new Promise(resolve => typeText(newSpan, textToType, 10, resolve));
        }

        async function processCommand(command) {
            await appendOutput(command, true);

            switch (command.toLowerCase()) {
                case 'help':
                    await appendOutput(`
                        Available Commands:
                        - fetch_live_data: Updates the visualizer with the latest inference data.
                        - analyze_anomalies: Runs an anomaly detection algorithm on current data.
                        - optimize_display: Adjusts visualization parameters for optimal clarity.
                        - model_status: Displays the status and version of the active neural network model.
                        - clear: Clears the terminal screen.
                        - exit: Returns to portfolio overview.
                    `);
                    break;
                case 'fetch_live_data':
                    playSound(dataTransferSound);
                    await appendOutput(`
                        &gt; [FETCH] Initiating Live Data Stream Fetch...
                        &gt; [INGEST] New Data Points Ingested: 7500 (from distributed sensors)
                        &gt; [PROCESS] Recalculating Predictive Models (GPU Accelerated)... [STATUS: DONE]
                        &gt; [DISPLAY] Updated Anomaly Clusters & Confidence Heatmaps.
                        &gt; [METRICS] Performance: Accuracy 99.5%, Latency 10ms.
                        &gt; [STATUS] Data Stream Updated.
                    `);
                    playSound(successSound);
                    break;
                case 'analyze_anomalies':
                    playSound(scanSound);
                    await appendOutput(`
                        &gt; [ANALYZE] Running Anomaly Detection Algorithm...
                        &gt; [SCAN] Data Set for Outliers and Deviations...
                        &gt; [REPORT] Detected 3 minor anomalies in sensor feed 7. Auto-correcting...
                        &gt; [STATUS] Anomaly Analysis Complete. System Stable.
                    `);
                    playSound(successSound);
                    break;
                case 'optimize_display':
                    await appendOutput(`
                        &gt; [OPTIMIZE] Adjusting Visualization Parameters...
                        &gt;   - Contrast: Auto-adjusted
                        &gt;   - Brightness: 80%
                        &gt;   - Refresh Rate: 120Hz
                        &gt; [STATUS] Display Optimized for Clarity.
                    `);
                    break;
                case 'model_status':
                    await appendOutput(`
                        &gt; [MODEL] Active Neural Network Model Status:
                        &gt;   - Model ID: NN-Predictor-v2.1
                        &gt;   - Training Epochs: 500
                        &gt;   - Last Update: 2024-07-15
                        &gt;   - Inference Engine: TensorFlow 2.x
                        &gt;   - Health: 100% (Optimal)
                    `);
                    break;
                case 'clear':
                    terminalOutput.innerHTML = '';
                    break;
                case 'exit':
                    playSound(buttonClickSound);
                    window.location.href = 'index.html';
                    break;
                default:
                    await appendOutput(`
                        &gt; [ERROR] Command not recognized: '${command}'. Type 'help' for a list of commands.
                    `);
                    playSound(accessDeniedSound);
            }
            terminalOutput.scrollTop = terminalOutput.scrollHeight;
        }
    </script>
</body>
</html>
